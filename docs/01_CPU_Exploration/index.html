<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lab 1: Exploring CPU Metrics with PromQL</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reset.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/theme/night.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/highlight/monokai.css">
    <link rel="stylesheet" href="../common.css">
</head>
<body>
    <div class="reveal">
        <div class="slides">
            <section data-markdown>
                <textarea data-template>
                    ## Lab 1: Exploring CPU Metrics with PromQL
                    
                    ðŸ”§ Basic PromQL
                    
                    <small>Navigate: [All Slides](../index.html)</small>
                    
<aside class="notes">
Welcome to Lab 1 of our PromQL series! In this session, we'll be focusing on exploring CPU metrics using Prometheus Query Language.

CPU metrics are often the first metrics people look at when troubleshooting performance issues, so understanding how to query them effectively is an essential skill for monitoring.

We'll build on the fundamentals we learned in Lab 0, applying those concepts to real-world CPU monitoring scenarios. By the end of this lab, you'll be comfortable exploring CPU metrics for your own systems.

Even if you're new to system monitoring, don't worry - we'll break down the concepts in a way that's easy to understand and apply.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Objectives
                    
                    * Learn how to find and filter basic metrics in Prometheus
                    * Understand the structure of `node_cpu_seconds_total`
                    * Practice using label filters
                    
<aside class="notes">
Our objectives for this lab are focused and practical:

First, we'll learn how to find and filter basic metrics in Prometheus. This is a fundamental skill - you need to know what metrics are available and how to find them before you can analyze them.

Next, we'll dig into the structure of the node_cpu_seconds_total metric. This is the main metric for CPU usage in Prometheus, and understanding its structure is key to writing effective CPU queries.

Finally, we'll get hands-on practice using label filters. As we'll see, CPU metrics have several important labels like 'mode' and 'cpu', and filtering by these labels is essential for meaningful analysis.

By the end of this lab, you'll have practical skills that you can immediately apply to monitoring CPU usage in your own environments.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Raw CPU Metrics
                    
                    ```promql
                    # Query the raw metric
                    node_cpu_seconds_total
                    ```
                    
                    * Returns many time series
                    * One for each CPU core and mode combination
                    * Counter type: always increasing
                    
<aside class="notes">
Let's start by looking at the raw CPU metrics in Prometheus.

When you query node_cpu_seconds_total, you'll immediately notice that it returns many time series - potentially dozens or even hundreds if you have multiple machines with multiple CPU cores.

Each time series represents a specific CPU core operating in a specific mode. For example, you might see one series for CPU 0 in user mode, another for CPU 0 in system mode, another for CPU 1 in user mode, and so on.

This metric is a counter type, which means it's always increasing. It counts the number of seconds each CPU has spent in each mode since the system started.

This raw form isn't very useful for direct analysis, but it's the foundation we'll build on to create meaningful CPU usage queries. We need to understand what we're working with before we can transform it into actionable insights.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Understanding CPU Metrics
                    
                    * `node_cpu_seconds_total` = CPU time since boot
                    * Labels provide context:
                        * `cpu` = Which core (0, 1, 2, ...)
                        * `mode` = Type of work (user, system, idle, ...)
                    * Values increase over time (counter)
                    
<aside class="notes">
Before we dive deeper into querying CPU metrics, let's make sure we understand what they represent.

The node_cpu_seconds_total metric tracks the total CPU time spent in various states since the system booted up. This is a raw counter that keeps increasing as long as the system is running.

What makes this metric powerful are its labels. The "cpu" label tells us which specific CPU core we're looking at - 0 for the first core, 1 for the second, and so on.

The "mode" label is particularly important as it tells us what kind of work the CPU was doing during that time. We'll look at these modes in detail in the next slide.

Remember that as a counter, the raw values just keep increasing and aren't directly useful. We'll need to calculate rates of change to get meaningful usage metrics, which we'll explore in Lab 2.

Understanding this structure is key to writing effective CPU queries in Prometheus.
</aside>
                </textarea>
            </section>
            
            <section data-markdown>
                <textarea data-template>
                    ## CPU Mode Types
                    
                    * **user** - Time spent in user space applications
                    * **system** - Time spent in kernel space (system calls)
                    * **idle** - Time CPU was not executing any code
                    * **iowait** - Time CPU waiting for I/O operations
                    * **irq/softirq** - Time handling hardware/software interrupts
                    * **steal** - Time other VMs "stole" from this VM (virtualization)
                    
<aside class="notes">
Let's look more closely at the different CPU modes that are tracked. Each mode tells us something different about what the CPU is doing:

The "user" mode represents time spent running user applications and processes. High user time usually means your applications are CPU-intensive.

"System" mode is time spent in kernel space, executing system calls. High system time might indicate excessive syscalls or kernel operations.

"Idle" mode is when the CPU isn't doing anything. This is actually important - it tells us how much spare capacity we have.

"IOWait" means the CPU is waiting for disk or network I/O operations to complete. High iowait could indicate a storage bottleneck.

"IRQ" and "softirq" represent time spent handling hardware and software interrupts, respectively. These could be elevated during high network traffic.

"Steal" is relevant in virtualized environments - it shows when your VM's CPU time was used by other VMs or the hypervisor. High steal time might indicate an oversubscribed host.

Understanding these modes helps you identify not just *if* you have a CPU issue, but *what kind* of CPU issue you're experiencing.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Filtering by Instance
                    
                    ```promql
                    # Filter by Instance
                    node_cpu_seconds_total{instance="localhost:9100"}
                    ```
                    
                    * Curly braces `{}` for filtering by label
                    * Great for multi-server environments
                    * Exact equality match using `=`
                    
<aside class="notes">
Now let's start filtering our CPU metrics to make them more manageable.

In a real-world environment, you'll likely be monitoring multiple servers or instances. The "instance" label in Prometheus identifies which specific server a metric is coming from.

The syntax for filtering is simple: put label filters inside curly braces. Here we're filtering to only see metrics from "localhost:9100", which is typically the node_exporter running on your local machine.

This exact equality matching with the equals sign is the most basic type of filtering. We've already seen in Lab 0 that you can also use regex matching with =~ for more flexible filtering.

In a production environment with dozens or hundreds of servers, this type of filtering is essential - you might filter for specific clusters, data centers, or application tiers to focus your analysis.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Filtering by CPU Mode
                    
                    ```promql
                    # Filter by CPU mode
                    node_cpu_seconds_total{instance="localhost:9100", mode="user"}
                    ```
                    
                    * Multiple label filters combined with AND logic
                    * Shows only user-space CPU consumption
                    * One time series per CPU core
                    
<aside class="notes">
Let's add another filter to focus on a specific CPU mode.

Here, we're adding a second label filter for mode="user". When you have multiple label filters like this, they're combined with AND logic - both conditions must be true for a metric to be included.

This query shows us only the user-mode CPU consumption - time spent running user applications rather than kernel code or being idle. This is often what you care most about when analyzing application performance.

Notice that we still get one time series per CPU core. If you have an 8-core system, you'll see 8 different time series, each showing the user-mode time for a different core.

Being able to filter by mode is powerful because different CPU modes tell you different things about your system's behavior. High system time might indicate kernel issues, while high iowait could point to storage bottlenecks.

You can try changing "user" to other modes like "system", "idle", or "iowait" to see different aspects of CPU usage.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Understanding the Results
                    
                    * Values continuously increase (they're counters)
                    * Different cores may show different patterns
                    * Raw values aren't directly useful for analysis
                    * Need to calculate rate of change for meaningful insights
                    
<aside class="notes">
Now that we've explored some basic CPU metrics, let's understand what the results tell us.

First, remember that these values are continuously increasing because they're counter metrics. They show cumulative CPU time since the system started, not current usage rates.

You might notice that different CPU cores show different patterns. This is normal - the operating system's scheduler distributes work across cores, but not always evenly. Some cores might be busier than others depending on how processes are scheduled.

Most importantly, these raw counter values aren't directly useful for analysis. Knowing that CPU 0 has spent 12,345 seconds in user mode since boot doesn't tell you much about current performance.

What we really need are rates of change - how fast these counters are increasing. That would tell us the current CPU utilization, which is what we actually care about for monitoring.

This is exactly what we'll learn in Lab 2, where we'll transform these raw counters into meaningful utilization percentages using PromQL rate functions.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Challenge: Compare Different Modes
                    
                    ```promql
                    # System mode - kernel operations
                    node_cpu_seconds_total{instance="localhost:9100", mode="system"}
                    
                    # Idle mode - CPU doing nothing
                    node_cpu_seconds_total{instance="localhost:9100", mode="idle"}
                    ```
                    
                    * `idle` values are typically much larger than others
                    * `system` values are usually lower than `user`
                    
<aside class="notes">
Let's put our knowledge into practice with a challenge: comparing different CPU modes.

Try running these two queries and compare the results. First, we look at system mode, which shows time spent in kernel operations. Then we look at idle mode, which shows time when the CPU wasn't doing anything.

You'll notice immediately that idle values are typically much larger than the others. This is expected - most servers spend a significant amount of time idle unless they're under heavy load.

You'll also notice that system values are usually lower than user values (which we saw earlier). This is normal too - most applications spend more time executing their own code than making system calls.

These comparisons help you understand the baseline behavior of your systems, making it easier to spot anomalies when they occur. For example, if system time suddenly becomes higher than user time, it might indicate a problem.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Insights from Mode Comparison
                    
                    * High `user` time = Application-heavy workload
                    * High `system` time = Heavy kernel operations (can indicate issues)
                    * Low `idle` time = High overall CPU utilization
                    * High `iowait` = Potential disk bottlenecks
                    * High `steal` = Overcommitted virtualization host
                    
<aside class="notes">
Let's summarize what different CPU mode patterns can tell us about our system's behavior.

High user time generally indicates an application-heavy workload. This is normal for most applications - they're doing what they're supposed to do.

High system time, especially if unusual for your workload, can indicate heavy kernel operations. This might point to issues like excessive syscalls, inefficient I/O, or other kernel-level problems.

Low idle time simply means high overall CPU utilization - your CPUs are busy. This could be good (efficient resource use) or bad (potential bottleneck), depending on your situation.

High iowait time suggests potential disk bottlenecks. Your CPU is sitting idle waiting for disk operations to complete. This could indicate slow disks, excessive I/O, or poorly optimized queries.

High steal time is specifically relevant in virtualized environments. It means the hypervisor is giving your VM's CPU time to other VMs or processes. This could indicate that your host is overcommitted.

Learning to read these patterns is like learning to read vital signs in medicine - they give you important diagnostic information about the health of your system.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    # ðŸŒŸ Great job!
                    
                    Continue to Lab 2: CPU Usage Rates
                    
                    <small>Navigate: [All Slides](../index.html) | [Next Lab](../02_CPU_Rates/index.html)</small>
                    
<aside class="notes">
Congratulations! You've completed Lab 1 on Exploring CPU Metrics with PromQL.

We've covered how to find and filter CPU metrics, understood the structure of node_cpu_seconds_total, and learned about different CPU modes and what they tell us about our system.

However, we're still working with raw counter values, which don't directly tell us about current CPU usage. To get meaningful CPU utilization metrics, we need to calculate rates of change.

That's exactly what we'll learn in Lab 2: CPU Usage Rates. We'll build on what we've learned here and transform these raw counters into practical utilization metrics that you can use for monitoring and alerting.

I encourage you to continue to Lab 2 to build these essential skills. If you want to explore other topics first, you can always return to the Slides Index.

Any questions before we wrap up this lab?
</aside>
                </textarea>
            </section>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reveal.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/markdown/markdown.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/highlight/highlight.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/notes/notes.js"></script>
    <script>
        Reveal.initialize({
            hash: true,
            transition: 'none', // Disable slide animations
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes],
            highlight: {
                highlightOnLoad: true,
                languages: ['promql']
            }
        });
    </script>
</body>
</html>
