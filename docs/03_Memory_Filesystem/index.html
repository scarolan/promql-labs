<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lab 3: Memory and Filesystem Usage</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reset.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/theme/night.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/monokai-sublime.css">
    <link rel="stylesheet" href="../common.css">
        .reveal pre code {
            padding: 20px;
            max-height: 400px;
            line-height: 1.2;
            font-size: 0.85em;
        }
        .reveal .smaller-text {
            font-size: 0.75em;
        }
        .reveal .smallest-text {
            font-size: 0.55em;
        }
        .reveal h1 {
            font-size: 2.2em;
        }
        .reveal h2 {
            font-size: 1.7em;
        }
        .reveal h3 {
            font-size: 1.3em;
        }
        .reveal ul, .reveal ol {
            display: block;
            line-height: 1.4;
        }
    </style>
</head>
<body>
    <div class="reveal">
        <div class="slides">
            <section data-markdown>
                <textarea data-template>
                    ## Lab 3: Memory and Filesystem Usage
                    
                    PromQL Labs
                    
                    <aside class="notes">
                        Welcome to Lab 3 of our PromQL series! Today we're moving beyond CPU metrics to explore two other critical system resources: memory and filesystem usage.
                        
                        While CPU metrics tell us about processing capacity, memory and filesystem metrics help us understand resource constraints that can affect application performance in different ways.
                        
                        In this lab, we'll learn how to query memory and disk metrics, calculate meaningful usage percentages, and visualize these in ways that make monitoring intuitive.
                        
                        Understanding these metrics is crucial for effective capacity planning, troubleshooting performance issues, and setting up meaningful alerts for your systems.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Objectives
                    
                    * Query and interpret memory and filesystem metrics
                    * Calculate memory usage percentage
                    * Visualize memory and disk usage in Grafana
                    
                    <aside class="notes">
                        Our objectives for this session are straightforward and practical:
                        
                        First, we'll learn how to query and interpret memory and filesystem metrics in Prometheus. These metrics are different from the CPU counters we worked with previously - they're primarily gauge metrics that show a point-in-time value rather than an ever-increasing counter.
                        
                        Next, we'll calculate memory usage percentage using PromQL. This is a common pattern in monitoring - taking raw metrics and transforming them into more meaningful indicators that directly answer questions like "How full is my system's memory?"
                        
                        Finally, we'll look at how to effectively visualize memory and disk usage in Grafana. We'll explore visualization types that are particularly well-suited for these metrics, such as gauges that give you an immediate visual indicator of resource usage levels.
                        
                        By the end of this session, you'll be able to set up comprehensive monitoring for memory and disk resources in your infrastructure.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Memory Metrics Basics
                    
                    ```promql
                    # Total system memory
                    node_memory_MemTotal_bytes{instance="localhost:9100"}
                    
                    # Available memory (can be allocated)
                    node_memory_MemAvailable_bytes{instance="localhost:9100"}
                    ```
                    
                    * Both are gauge metrics (can go up and down)
                    * Measured in bytes
                    * MemAvailable is what applications can use
                    
                    <aside class="notes">
                        Let's start with the basics of memory metrics in Prometheus.
                        
                        The two most fundamental memory metrics are MemTotal and MemAvailable. MemTotal shows the total physical memory on your system, while MemAvailable shows how much memory can be allocated to new applications right now.
                        
                        Unlike the CPU metrics we saw earlier, which were counters, memory metrics are gauge metrics. This means they can go both up and down, and they represent a point-in-time value rather than an accumulating total.
                        
                        Both metrics are measured in bytes, which is the standard unit for memory in Prometheus. You'll often need to convert these to more human-readable units like gigabytes when presenting them.
                        
                        It's important to understand that MemAvailable is not the same as "free" memory. It includes memory that is currently used for caching but can be reclaimed if needed by applications. This makes it a much better indicator of actual memory pressure than simply looking at unused memory.
                        
                        In modern Linux systems, MemAvailable is calculated by the kernel to give a realistic picture of how much memory is truly available for new allocations, taking into account page cache, reclaimable slab memory, and other factors.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Memory: Beyond Total and Available
                    
                    * **MemTotal**: All physical RAM
                    * **MemFree**: Completely unused memory
                    * **MemAvailable**: Can be allocated (includes reclaimable)
                    * **Buffers**: Temporary storage for raw I/O
                    * **Cached**: Page cache (file contents)
                    * **SwapTotal/SwapFree**: Virtual memory on disk
                    
                    <aside class="notes">
                        While MemTotal and MemAvailable are the most commonly used memory metrics, there are several other important metrics that give us a more complete picture of memory usage.
                        
                        MemFree represents memory that is completely unused - it's sitting idle with nothing in it. This is different from MemAvailable, which includes memory that's currently being used but can be reclaimed if needed.
                        
                        Buffers represent memory used for temporary storage of raw disk blocks. This is used by the kernel for I/O operations.
                        
                        Cached memory contains file data that has been read from disk and kept in memory for faster access. This is very important in Linux systems - "free" memory is often used for caching to improve performance, but this cached memory can be reclaimed when applications need it.
                        
                        SwapTotal and SwapFree tell us about virtual memory on disk. When physical memory gets low, the system can move less frequently used memory pages to disk. High swap usage often indicates memory pressure and can cause performance issues due to the much slower access times of disk compared to RAM.
                        
                        Understanding these different memory categories helps you diagnose memory-related performance issues more effectively. For example, if you see high memory usage but most of it is cached, that's usually not a problem. But if you see high memory usage and increasing swap activity, that indicates true memory pressure.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Calculating Memory Usage Percentage
                    
                    ```promql
                    # Memory usage as a percentage
                    100 * (1 - (node_memory_MemAvailable_bytes{instance="localhost:9100"} / 
                    node_memory_MemTotal_bytes{instance="localhost:9100"}))
                    ```
                    
                    * Formula pattern: `100 * (1 - available/total)`
                    * Result: Percentage of memory currently in use
                    * Better than `MemFree` because it accounts for cache
                    
                    <aside class="notes">
                        Now let's look at how to calculate memory usage as a percentage, which is more intuitive than raw byte values.
                        
                        The formula follows a common pattern we'll use throughout this lab: we take the fraction of memory that's available (available divided by total), subtract it from 1 to get the fraction that's used, and multiply by 100 to convert to a percentage.
                        
                        The result gives us the percentage of memory currently in use, which is much easier to interpret than raw byte values. For instance, knowing that your system is using 70% of its memory gives you an immediate sense of the memory pressure, whereas a value like "12 gigabytes used out of 16 gigabytes total" requires more mental calculation.
                        
                        This formula is better than using MemFree because it accounts for cached memory. If we only considered completely free memory, we might think the system is running out of memory when in fact there's plenty of reclaimable memory available in the cache.
                        
                        This is the formula I recommend using for monitoring and alerting on memory usage. You might set alerts at different thresholds - perhaps a warning alert at 80% and a critical alert at 90% - but the exact thresholds will depend on your specific applications and their memory usage patterns.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Memory Usage: Best Practices
                    
                    * **Use `MemAvailable` not `MemFree`**
                      * Accounts for reclaimable memory
                      * More accurate representation of true memory pressure
                    
                    * **Monitor swap usage separately**
                      * High swap usage often indicates memory problems
                    
                    * **Set thresholds based on application needs**
                      * Different applications have different memory patterns
                    
                    <aside class="notes">
                        Let's discuss some best practices for monitoring memory usage that I've learned from experience.
                        
                        First, always use MemAvailable instead of MemFree for calculating memory usage. This is crucial because Linux uses available memory for caching to improve performance. Using MemFree would make it appear that you're constantly low on memory when in fact much of that "used" memory can be reclaimed instantly if needed.
                        
                        Second, make sure to monitor swap usage separately from main memory. Increased swap activity often indicates memory pressure even when memory usage metrics look acceptable. Excessive swapping, or "thrashing," can severely impact performance as the system constantly moves memory pages between RAM and disk.
                        
                        Third, set your memory usage thresholds based on the specific needs of your applications. Some applications, like databases, need plenty of memory for caching and might legitimately use 80-90% of memory. Others might start experiencing problems at much lower utilization levels. Understanding your application's memory usage patterns is key to setting meaningful alerts.
                        
                        Another practice I recommend is monitoring memory usage trends over time, not just current values. A steady increase in memory usage might indicate a memory leak that will eventually cause problems, even if current usage is within acceptable limits.
                        
                        Finally, remember that memory issues can manifest in different ways - high memory usage, increased swap activity, or even increased system CPU time as the kernel spends more time managing memory. Monitoring all these aspects gives you a more complete picture of memory health.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Filesystem Metrics Basics
                    
                    ```promql
                    # Total size of filesystems (excluding tmpfs)
                    node_filesystem_size_bytes{instance="localhost:9100",fstype!="tmpfs",mountpoint!="/run"}
                    
                    # Free space on filesystems
                    node_filesystem_free_bytes{instance="localhost:9100",fstype!="tmpfs",mountpoint!="/run"}
                    ```
                    
                    * Filters exclude temporary filesystems
                    * Both are gauge metrics
                    
                    <aside class="notes">
                        Now let's turn our attention to filesystem metrics in Prometheus.
                        
                        The two most fundamental filesystem metrics are node_filesystem_size_bytes, which shows the total size of each filesystem, and node_filesystem_free_bytes, which shows how much free space is available on each filesystem.
                        
                        Notice that in our queries, we're filtering with fstype!="tmpfs" and mountpoint!="/run". This excludes temporary filesystems like tmpfs, which exist only in memory and aren't relevant for disk capacity monitoring. We want to focus on persistent storage.
                        
                        Like memory metrics, filesystem metrics are gauge metrics that represent point-in-time values rather than counters. The values can go up when you add storage or down as you use more disk space.
                        
                        One thing to be aware of with filesystem metrics is that they come with several labels that identify the specific filesystem. The most important ones are "mountpoint", which tells you where the filesystem is mounted (like "/" for the root filesystem), and "fstype", which tells you what kind of filesystem it is (like "ext4", "xfs", etc.).
                        
                        These labels are crucial for filtering and targeting specific filesystems in your monitoring and alerts. For instance, you might want different alerts for your root filesystem versus your data storage filesystems.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Calculating Disk Usage Percentage
                    
                    ```promql
                    # Disk usage percentage for root filesystem
                    100 * (1 - (node_filesystem_free_bytes{instance="localhost:9100",mountpoint="/"} /
                    node_filesystem_size_bytes{instance="localhost:9100",mountpoint="/"}))
                    ```
                    
                    * Similar pattern to memory calculation
                    * Filter by `mountpoint="/"` for root filesystem
                    * Critical metric for capacity planning
                    
                    <aside class="notes">
                        Just as with memory, we typically want to calculate disk usage as a percentage rather than working with raw byte values.
                        
                        The formula follows the same pattern we used for memory: we take the fraction of disk that's free (free bytes divided by total size), subtract it from 1 to get the fraction that's used, and multiply by 100 to get a percentage.
                        
                        In this example, we're specifically targeting the root filesystem by filtering with mountpoint="/". This is important because most systems have multiple filesystems, and you want to monitor each one separately.
                        
                        Disk usage percentage is a critical metric for capacity planning. Running out of disk space can cause severe problems - applications may crash, logs may stop being written, and in extreme cases, the entire system might become unresponsive.
                        
                        When monitoring disk usage, it's common to set alerts at higher thresholds than for memory - perhaps warning at 85% and critical at 90% or 95%. This gives you time to respond before the disk completely fills up.
                        
                        Remember that different filesystems may need different thresholds. For example, a filesystem dedicated to logs might normally run at higher utilization and need a higher threshold, while your root filesystem might need more free space to function properly.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Filesystem Monitoring Best Practices
                    
                    * **Monitor all important mount points**
                      * Root, data, log directories, etc.
                    
                    * **Set different thresholds for different filesystems**
                      * Root filesystem: Alert at 85-90%
                      * Log filesystems: May need higher thresholds
                    
                    * **Watch for growth trends**
                      * Use `predict_linear()` for capacity planning
                    
                    <aside class="notes">
                        Let's discuss some best practices for filesystem monitoring that I've found valuable in production environments.
                        
                        First, make sure you monitor all important mount points, not just the root filesystem. This includes dedicated partitions for data, logs, backups, and any other critical storage. Each of these might have different growth patterns and importance.
                        
                        Second, set appropriate thresholds for different filesystems. The root filesystem might need more free space to function properly, so you might set alerts at 85-90% usage. Log filesystems, on the other hand, might normally run at higher utilization, so you might set thresholds at 95% or even higher.
                        
                        Third, and perhaps most importantly, watch for growth trends over time. A filesystem that's slowly growing will eventually fill up, even if current usage is acceptable. This is where Prometheus's predict_linear() function becomes invaluable.
                        
                        With predict_linear(), you can forecast when a filesystem will run out of space based on recent growth trends. For example, you might create an alert that fires if a filesystem is predicted to fill up within the next 7 days, giving you time to address the issue before it becomes critical.
                        
                        Finally, remember that filesystem monitoring isn't just about capacity - it's also about performance. High I/O wait times can indicate disk performance issues that might require different solutions than just adding more capacity.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Visualizing with Gauges in Grafana
                    
                    * Gauges provide at-a-glance status
                    * Good for metrics with clear thresholds
                    * Set meaningful color thresholds:
                      * Green: Normal (0-70%)
                      * Yellow: Warning (70-85%)
                      * Red: Critical (85-100%)
                    
                    <aside class="notes">
                        When it comes to visualizing memory and disk usage in Grafana, gauge visualizations are particularly effective.
                        
                        Gauges provide an at-a-glance status that's immediately understandable, even to non-technical users. You can see in an instant whether a system is in a healthy state or approaching capacity limits.
                        
                        Gauges work best for metrics with clear thresholds, like memory and disk usage percentages. They're less useful for metrics that don't have clear "good" and "bad" values.
                        
                        One of the most powerful features of Grafana gauges is the ability to set color thresholds. A common pattern is to use green for normal levels (0-70%), yellow for warning levels (70-85%), and red for critical levels (85-100%). These colors provide immediate visual feedback on the state of your systems.
                        
                        When creating gauges, make sure to set appropriate minimum and maximum values - usually 0 and 100 for percentages. You might also want to adjust the thresholds based on the specific metric and your operational requirements.
                        
                        While gauges are great for current status, remember to pair them with time series graphs that show historical trends. The gauge tells you the current state, while the graph shows how you got there and where you might be heading.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Complete Dashboard Example
                    
                    * Memory gauge + graph (shows history)
                    * Disk usage gauge + graph
                    * Swap usage if relevant
                    * Top processes by memory (requires process exporter)
                    * Can combine with CPU metrics from earlier labs
                    
                    <aside class="notes">
                        Let's talk about how you might build a complete resource monitoring dashboard in Grafana using what we've learned so far.
                        
                        A well-designed dashboard typically includes both gauges and graphs for each key metric. For memory, you might have a gauge showing current usage percentage alongside a time series graph showing usage over the past 24 hours or week.
                        
                        Similarly, for disk usage, you'd have gauges for each important filesystem plus graphs showing trends. The combination gives you both immediate status and historical context.
                        
                        If your system uses swap space, include a panel for swap usage. High swap utilization often indicates memory pressure even when memory usage itself doesn't look alarming.
                        
                        For more detailed analysis, you can add panels showing the top processes by memory usage. This requires the process exporter or a similar tool that exposes process-level metrics to Prometheus. This helps you identify which specific processes are consuming your resources.
                        
                        Finally, consider combining these memory and filesystem metrics with the CPU metrics we explored in earlier labs. The combination gives you a complete picture of system resource usage, helping you identify whether performance issues are CPU-bound, memory-bound, or I/O-bound.
                        
                        The best dashboards tell a story - they don't just show numbers, but help you understand what's happening on your systems at a glance.
                    </aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Continue Learning
                    
                    * [Continue to Lab 4: Network, Load, and Advanced Aggregations](../04_Network_Load/index.html)
                    * [Return to Slides Index](../index.html)
                    
                    <aside class="notes">
                        Congratulations! You've completed Lab 3 and now have a solid understanding of how to monitor memory and filesystem usage with Prometheus and Grafana.
                        
                        We've learned how to query memory and filesystem metrics, calculate usage percentages, and visualize these metrics effectively. These skills are directly applicable to real-world monitoring scenarios.
                        
                        To continue your PromQL journey, proceed to Lab 4 where we'll explore network metrics, system load, and advanced aggregation techniques. These will round out your core monitoring capabilities and introduce some more advanced PromQL concepts.
                        
                        If you want to review the overall curriculum, you can return to the Slides Index.
                        
                        Remember that effective resource monitoring is about more than just collecting metrics - it's about transforming those metrics into actionable insights that help you maintain healthy systems and quickly identify problems when they arise.
                        
                        Any questions before we wrap up this session?
                    </aside>
                </textarea>
            </section>
        </div>
    </div>
    
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reveal.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/markdown/markdown.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/highlight/highlight.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/notes/notes.js"></script>
    <script>
        Reveal.initialize({
            hash: true,
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes],
            highlight: {
                highlightOnLoad: true,
                languages: ['promql']
            }
        });
    </script>
</body>
</html>
