<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lab 3: Memory and Filesystem Usage</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reset.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/theme/night.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/highlight/monokai.css">
    <link rel="stylesheet" href="../common.css">
</head>
<body>
    <div class="reveal">
        <div class="slides">
            <section data-markdown>
                <textarea data-template>
                    ## Lab 3: Memory and Filesystem Usage
                    
                    PromQL Labs
                    
<aside class="notes">
Welcome to Lab 3 of our PromQL series! Today we're moving beyond CPU metrics to explore two other critical system resources: memory and filesystem usage.

While CPU metrics tell us about processing capacity, memory and filesystem metrics help us understand resource constraints that can affect application performance in different ways.

In this lab, we'll learn how to query memory and disk metrics, calculate meaningful usage percentages, and visualize these in ways that make monitoring intuitive.

Understanding these metrics is crucial for effective capacity planning, troubleshooting performance issues, and setting up meaningful alerts for your systems.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Objectives
                    
                    * Query and interpret memory and filesystem metrics
                    * Calculate memory usage percentage
                    * Visualize memory and disk usage in Grafana
                    
<aside class="notes">
Our objectives for this session are straightforward and practical:

First, we'll learn how to query and interpret memory and filesystem metrics in Prometheus. These metrics are different from the CPU counters we worked with previously - they're primarily gauge metrics that show a point-in-time value rather than an ever-increasing counter.

Next, we'll calculate memory usage percentage using PromQL. This is a common pattern in monitoring - taking raw metrics and transforming them into more meaningful indicators that directly answer questions like "How full is my system's memory?"

Finally, we'll look at how to effectively visualize memory and disk usage in Grafana. We'll explore visualization types that are particularly well-suited for these metrics, such as gauges that give you an immediate visual indicator of resource usage levels.

By the end of this session, you'll be able to set up comprehensive monitoring for memory and disk resources in your infrastructure.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Memory Metrics Basics
                    
                    ```promql
                    # Total system memory
                    node_memory_MemTotal_bytes{instance="localhost:9100"}
                    
                    # Available memory (can be allocated)
                    node_memory_MemAvailable_bytes{instance="localhost:9100"}
                    ```
                    
                    * Both are gauge metrics (can go up and down)
                    * Measured in bytes
                    * MemAvailable is what applications can use
                    
<aside class="notes">
Let's start with the basics of memory metrics in Prometheus.

The two most fundamental memory metrics are MemTotal and MemAvailable. MemTotal shows the total physical memory on your system, while MemAvailable shows how much memory can be allocated to new applications right now.

Unlike the CPU metrics we saw earlier, which were counters, memory metrics are gauge metrics. This means they can go both up and down, and they represent a point-in-time value rather than an accumulating total.

Both metrics are measured in bytes, which is the standard unit for memory in Prometheus. You'll often need to convert these to more human-readable units like gigabytes when presenting them.

It's important to understand that MemAvailable is not the same as "free" memory. It includes memory that is currently used for caching but can be reclaimed if needed by applications. This makes it a much better indicator of actual memory pressure than simply looking at unused memory.

In modern Linux systems, MemAvailable is calculated by the kernel to give a realistic picture of how much memory is truly available for new allocations, taking into account page cache, reclaimable slab memory, and other factors.
</aside>
                </textarea>
            </section>

            <section data-markdown class="dense-content">
                <textarea data-template>
                    ## Memory: Beyond Total and Available
                    
                    * **MemTotal**: All physical RAM
                    * **MemFree**: Completely unused memory
                    * **MemAvailable**: Can be allocated (includes reclaimable)
                    * **Buffers**: Temporary storage for raw I/O
                    * **Cached**: Page cache (file contents)
                    * **SwapTotal/SwapFree**: Virtual memory on disk
                    
<aside class="notes">
Different memory categories helps you diagnose memory-related performance issues more effectively. For example, if you see high memory usage but most of it is cached, that's usually not a problem. But if you see high memory usage and increasing swap activity, that indicates true memory pressure.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Calculating Memory Usage Percentage
                    
                    ```promql
                    # Memory usage as a percentage
                    100 * (1 - (node_memory_MemAvailable_bytes{instance="localhost:9100"} / 
                    node_memory_MemTotal_bytes{instance="localhost:9100"}))
                    ```
                    
                    * Formula pattern: `100 * (1 - available/total)`
                    * Result: Percentage of memory currently in use
                    * Better than `MemFree` because it accounts for cache
                    
<aside class="notes">
Now let's look at how to calculate memory usage as a percentage, which is more intuitive than raw byte values.

The formula follows a common pattern we'll use throughout this lab: we take the fraction of memory that's available (available divided by total), subtract it from 1 to get the fraction that's used, and multiply by 100 to convert to a percentage.

The result gives us the percentage of memory currently in use, which is much easier to interpret than raw byte values. For instance, knowing that your system is using 70% of its memory gives you an immediate sense of the memory pressure, whereas a value like "12 gigabytes used out of 16 gigabytes total" requires more mental calculation.

This formula is better than using MemFree because it accounts for cached memory. If we only considered completely free memory, we might think the system is running out of memory when in fact there's plenty of reclaimable memory available in the cache.

This is the formula I recommend using for monitoring and alerting on memory usage. You might set alerts at different thresholds - perhaps a warning alert at 80% and a critical alert at 90% - but the exact thresholds will depend on your specific applications and their memory usage patterns.
</aside>
                </textarea>
            </section>

            <section data-markdown class="dense-content">
                <textarea data-template>
                    ## Memory Usage: Best Practices
                    
                    * **Use `MemAvailable` not `MemFree`**
                      * Accounts for reclaimable memory
                      * More accurate representation of true memory pressure
                    
                    * **Monitor swap usage separately**
                      * High swap usage often indicates memory problems
                    
                    * **Set thresholds based on application needs**
                      * Different applications have different memory patterns
                    
<aside class="notes">
Let's discuss some best practices for monitoring memory usage that I've learned from experience.

First, always use MemAvailable instead of MemFree for calculating memory usage. This is crucial because Linux uses available memory for caching to improve performance. Using MemFree would make it appear that you're constantly low on memory when in fact much of that "used" memory can be reclaimed instantly if needed.

Second, make sure to monitor swap usage separately from main memory. Increased swap activity often indicates memory pressure even when memory usage metrics look acceptable. Excessive swapping, or "thrashing," can severely impact performance as the system constantly moves memory pages between RAM and disk.

Third, set your memory usage thresholds based on the specific needs of your applications. Some applications, like databases, need plenty of memory for caching and might legitimately use 80-90% of memory. Others might start experiencing problems at much lower utilization levels. Understanding your application's memory usage patterns is key to setting meaningful alerts.

Another practice I recommend is monitoring memory usage trends over time, not just current values. A steady increase in memory usage might indicate a memory leak that will eventually cause problems, even if current usage is within acceptable limits.

Finally, remember that memory issues can manifest in different ways - high memory usage, increased swap activity, or even increased system CPU time as the kernel spends more time managing memory. Monitoring all these aspects gives you a more complete picture of memory health.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Filesystem Metrics Basics
                    
                    ```promql
                    # Total size of filesystems (excluding tmpfs)
                    node_filesystem_size_bytes{instance="localhost:9100",fstype!="tmpfs",mountpoint!="/run"}
                    
                    # Free space on filesystems
                    node_filesystem_free_bytes{instance="localhost:9100",fstype!="tmpfs",mountpoint!="/run"}
                    ```
                    
                    * Filters exclude temporary filesystems
                    * Both are gauge metrics
                    
<aside class="notes">
Now let's turn our attention to filesystem metrics in Prometheus.

The two most fundamental filesystem metrics are node_filesystem_size_bytes, which shows the total size of each filesystem, and node_filesystem_free_bytes, which shows how much free space is available on each filesystem.

Notice that in our queries, we're filtering with fstype!="tmpfs" and mountpoint!="/run". This excludes temporary filesystems like tmpfs, which exist only in memory and aren't relevant for disk capacity monitoring. We want to focus on persistent storage.

Like memory metrics, filesystem metrics are gauge metrics that represent point-in-time values rather than counters. The values can go up when you add storage or down as you use more disk space.

One thing to be aware of with filesystem metrics is that they come with several labels that identify the specific filesystem. The most important ones are "mountpoint", which tells you where the filesystem is mounted (like "/" for the root filesystem), and "fstype", which tells you what kind of filesystem it is (like "ext4", "xfs", etc.).

These labels are crucial for filtering and targeting specific filesystems in your monitoring and alerts. For instance, you might want different alerts for your root filesystem versus your data storage filesystems.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Calculating Disk Usage Percentage
                    
                    ```promql
                    # Disk usage percentage for root filesystem
                    100 * (1 - (node_filesystem_free_bytes{instance="localhost:9100",mountpoint="/"} /
                    node_filesystem_size_bytes{instance="localhost:9100",mountpoint="/"}))
                    ```
                    
                    * Similar pattern to memory calculation
                    * Filter by `mountpoint="/"` for root filesystem
                    * Critical metric for capacity planning
                    
<aside class="notes">
Just as with memory, we typically want to calculate disk usage as a percentage rather than working with raw byte values.

The formula follows the same pattern we used for memory: we take the fraction of disk that's free (free bytes divided by total size), subtract it from 1 to get the fraction that's used, and multiply by 100 to get a percentage.

In this example, we're specifically targeting the root filesystem by filtering with mountpoint="/". This is important because most systems have multiple filesystems, and you want to monitor each one separately.

Disk usage percentage is a critical metric for capacity planning. Running out of disk space can cause severe problems - applications may crash, logs may stop being written, and in extreme cases, the entire system might become unresponsive.

When monitoring disk usage, it's common to set alerts at higher thresholds than for memory - perhaps warning at 85% and critical at 90% or 95%. This gives you time to respond before the disk completely fills up.

Remember that different filesystems may need different thresholds. For example, a filesystem dedicated to logs might normally run at higher utilization and need a higher threshold, while your root filesystem might need more free space to function properly.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Filesystem Monitoring Best Practices
                    
                    * **Monitor all important mount points**
                      * Root, data, log directories, etc.
                    
                    * **Set different thresholds for different filesystems**
                      * Root filesystem: Alert at 85-90%
                      * Log filesystems: May need higher thresholds
                    
                    * **Watch for growth trends**
                      * Use `predict_linear()` for capacity planning
                    
<aside class="notes">
Let's discuss some best practices for filesystem monitoring that I've found valuable in production environments.

First, make sure you monitor all important mount points, not just the root filesystem. This includes dedicated partitions for data, logs, backups, and any other critical storage. Each of these might have different growth patterns and importance.

Second, set appropriate thresholds for different filesystems. The root filesystem might need more free space to function properly, so you might set alerts at 85-90% usage. Log filesystems, on the other hand, might normally run at higher utilization, so you might set thresholds at 95% or even higher.

Third, and perhaps most importantly, watch for growth trends over time. A filesystem that's slowly growing will eventually fill up, even if current usage is acceptable. This is where Prometheus's predict_linear() function becomes invaluable.

With predict_linear(), you can forecast when a filesystem will run out of space based on recent growth trends. For example, you might create an alert that fires if a filesystem is predicted to fill up within the next 7 days, giving you time to address the issue before it becomes critical.

Finally, remember that filesystem monitoring isn't just about capacity - it's also about performance. High I/O wait times can indicate disk performance issues that might require different solutions than just adding more capacity.
</aside>
                </textarea>
            </section>

            <section data-markdown class="dense-content">
                <textarea data-template>
                    ## Visualizing with Gauges in Grafana
                    
                    * Gauges provide at-a-glance status
                    * Good for metrics with clear thresholds
                    * Set meaningful color thresholds:
                      * Green: Normal (0-70%)
                      * Yellow: Warning (70-85%)
                      * Red: Critical (85-100%)
                    
<aside class="notes">
When it comes to visualizing memory and disk usage in Grafana, gauge visualizations are particularly effective.

Gauges provide an at-a-glance status that's immediately understandable, even to non-technical users. You can see in an instant whether a system is in a healthy state or approaching capacity limits.

Gauges work best for metrics with clear thresholds, like memory and disk usage percentages. They're less useful for metrics that don't have clear "good" and "bad" values.

One of the most powerful features of Grafana gauges is the ability to set color thresholds. A common pattern is to use green for normal levels (0-70%), yellow for warning levels (70-85%), and red for critical levels (85-100%). These colors provide immediate visual feedback on the state of your systems.

When creating gauges, make sure to set appropriate minimum and maximum values - usually 0 and 100 for percentages. You might also want to adjust the thresholds based on the specific metric and your operational requirements.

While gauges are great for current status, remember to pair them with time series graphs that show historical trends. The gauge tells you the current state, while the graph shows how you got there and where you might be heading.
</aside>
                </textarea>
            </section>

            <section data-markdown class="dense-content">
                <textarea data-template>
                    ## Complete Dashboard Example
                    
                    * Memory gauge + graph (shows history)
                    * Disk usage gauge + graph
                    * Swap usage if relevant
                    * Top processes by memory (requires process exporter)
                    * Can combine with CPU metrics from earlier labs
                    
<aside class="notes">
Let's talk about how you might build a complete resource monitoring dashboard in Grafana using what we've learned so far.

A well-designed dashboard typically includes both gauges and graphs for each key metric. For memory, you might have a gauge showing current usage percentage alongside a time series graph showing usage over the past 24 hours or week.

Similarly, for disk usage, you'd have gauges for each important filesystem plus graphs showing trends. The combination gives you both immediate status and historical context.

If your system uses swap space, include a panel for swap usage. High swap utilization often indicates memory pressure even when memory usage itself doesn't look alarming.

For more detailed analysis, you can add panels showing the top processes by memory usage. This requires the process exporter or a similar tool that exposes process-level metrics to Prometheus. This helps you identify which specific processes are consuming your resources.

Finally, consider combining these memory and filesystem metrics with the CPU metrics we explored in earlier labs. The combination gives you a complete picture of system resource usage, helping you identify whether performance issues are CPU-bound, memory-bound, or I/O-bound.

The best dashboards tell a story - they don't just show numbers, but help you understand what's happening on your systems at a glance.
</aside>
                </textarea>
            </section>

            <section data-markdown class="dense-content">
                <textarea data-template>
                    ## Challenge: Visualize as Gauges

                    ![Grafana Gauge](https://grafana.com/media/docs/grafana/panels-visualizations/screenshot-gauge-visualization-v11.4.png)
                    
                    * Try visualizing memory and disk usage as gauges in Grafana
                    * Gauge visualization is perfect for percentage metrics
                    * Set appropriate thresholds for warning and critical levels
                       
<aside class="notes">
Now, let's apply what we've learned with a practical challenge.

Your task is to create gauge visualizations for memory and disk usage in Grafana. Gauge visualizations are perfect for percentage metrics like these because they provide an instant visual indicator of resource utilization.

To complete this challenge, you'll need to:
1. Create a new Grafana panel with the gauge visualization
2. Use the memory usage percentage query we just created
3. Set appropriate thresholds - perhaps green for normal usage (0-70%), yellow for warning levels (70-85%), and red for critical levels (85-100%)
4. Repeat the process for disk usage with similar thresholds

Gauges are particularly effective for metrics with well-defined thresholds. They allow operators to quickly assess system health without needing to interpret line graphs. When a gauge is in the red zone, it immediately communicates that attention is needed.

Give it a try, and we'll review a solution in a moment.
</aside>
                </textarea>
            </section>

            <section data-markdown class="dense-content">
                <textarea data-template>
                    ## Solution
                    
                    ```
                    # Memory Usage Gauge Query:
                    100 * (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))
                    ```

                    ```
                    # Disk Usage Gauge Query:
                    100 * (1 - (
                        node_filesystem_free_bytes{mountpoint="/"} / 
                        node_filesystem_size_bytes{mountpoint="/"}
                    ))
                    ```
                    
                    * Set thresholds:
                      * Green: 0-70%
                      * Yellow: 70-85%
                      * Red: 85-100%
                    
<aside class="notes">
Here's how you would implement the solution to our gauge visualization challenge.

For the memory usage gauge, you'd use the query we created earlier to calculate the percentage of memory used. The thresholds provide a clear visual indication: green means normal usage, yellow indicates you're getting close to capacity, and red means you're at risk of memory pressure issues.

For the disk usage gauge, we follow a similar pattern, calculating the percentage of disk space used on the root filesystem. Again, we use color-coded thresholds to make the visualization immediately actionable.

In a production environment, you might even connect these gauges to alerting rules. For example, you could set up an alert to trigger when memory usage exceeds 85% for more than 10 minutes.

Arranging these gauges side by side on your dashboard gives you an at-a-glance overview of your system's resource usage. This is especially valuable for operators who need to quickly assess system health across many servers.

Remember, effective monitoring isn't just about collecting data - it's about presenting it in a way that enables quick, informed decisions. Gauge visualizations are one powerful tool in that toolkit.
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    ## Continue Learning
                    
                    * [Continue to Lab 4: Network, Load, and Advanced Aggregations](../04_Network_Load/index.html)
                    * [Return to Slides Index](../index.html)
                    
<aside class="notes">
Congratulations! You've completed Lab 3 and now have a solid understanding of how to monitor memory and filesystem usage with Prometheus and Grafana.

We've learned how to query memory and filesystem metrics, calculate usage percentages, and visualize these metrics effectively. These skills are directly applicable to real-world monitoring scenarios.

To continue your PromQL journey, proceed to Lab 4 where we'll explore network metrics, system load, and advanced aggregation techniques. These will round out your core monitoring capabilities and introduce some more advanced PromQL concepts.

If you want to review the overall curriculum, you can return to the Slides Index.

Remember that effective resource monitoring is about more than just collecting metrics - it's about transforming those metrics into actionable insights that help you maintain healthy systems and quickly identify problems when they arise.

Any questions before we wrap up this session?
</aside>
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    # 🌟 Great job!

                    <small>Navigate: [All Slides](../index.html) | [Next Lab](../04_Network_Load/index.html)</small>
                    
<aside class="notes">
Great job completing Lab 3 on Memory and Filesystem Usage!

You've now expanded your PromQL toolkit to include memory and filesystem metrics, which are essential components of system monitoring. You can calculate usage percentages for both memory and disk space, and you know how to visualize these effectively in Grafana.

These skills build on what you learned in the previous CPU-focused labs, giving you a more comprehensive view of system resources. Memory, disk, and CPU metrics together provide a complete picture of system health and performance.

In the next lab, we'll round out your core monitoring skills by exploring network metrics and system load. We'll also introduce some more advanced aggregation techniques that will help you handle metrics at scale.

I encourage you to continue to Lab 4 to build on what you've learned. If you want to explore other topics first, you can always return to the Slides Index.

Any questions before we move on?
</aside>
                </textarea>
            </section>
        </div>
    </div>
    
    <!-- Include common scripts -->
    <script src="../common-scripts.js"></script>
</body>
</html>
